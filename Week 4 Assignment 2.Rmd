---
title: "Week 4 Part 2"
author: "Peter Lombardo"
date: "June 29, 2018"
output: html_document
---

```{r}
suppressWarnings(suppressMessages(library("tm")))
suppressWarnings(suppressMessages(library("RTextTools")))
suppressWarnings(suppressMessages(library("tidyverse")))
suppressWarnings(suppressMessages(library("stringr")))
suppressWarnings(suppressMessages(library("SnowballC")))
suppressWarnings(suppressMessages(library("wordcloud")))
suppressWarnings(suppressMessages(library("devtools")))
suppressWarnings(suppressMessages(library("Rfacebook")))
suppressWarnings(suppressMessages(library("RCurl")))
suppressWarnings(suppressMessages(library("rjson")))
suppressWarnings(suppressMessages(library("quanteda")))
suppressWarnings(suppressMessages(library("magrittr")))
```
```{r}
 setwd("C:/Users/Peter/Google Drive/CUNY/DATA 620/Week 4")
```
```{r}
url<-  "https://graph.facebook.com/v3.0/10155718075607781/comments?pretty=0&limit=2000&after=QVFIUnI4WXhfX1FSeWtmSEt0c21sRTdPV3N0elM5azBOdnBFNEhTU3lDR1NiT3NIOHF6SnNHVHlHMlM5VjNoakpCQUQ2dHVyMGdXbm9rTkNxSVV4UENuVWpn&access_token=EAACEdEose0cBAGrPAqnexrpdUCv4BPFPXx3ezKYR57JkvAxn5NXdkvpBgPZBOKhAE3o8z0AuthDbrK3Kj8zYNXh6ZB6AL9PvsdcGZAuQOjYbwhIexGzVMLBip0xNh45m2nwGRwpIDqbmkAx5Fzh17DJItclSwYmxyro2Bczw43wyQ5BzjJ0pzpeXEdS2GWgtlRDP9dHdAZDZD"
d<-getURL(url)
j<-fromJSON(d)
```
```{r}
comments<-sapply(j$data,function(j){list(comment =j$message)})
commnets_clean <-sapply(comments,function(x)iconv(enc2utf8(x),sub = "byte"))
stopwords_regex = paste(stopwords('en'), collapse = '\\b|\\b')
stopwords_regex = paste0('\\b', stopwords_regex, '\\b')
commnets_clean = stringr::str_replace_all(commnets_clean, stopwords_regex, '')
commnets_clean2 <- unlist(strsplit(commnets_clean, split=", "))
commnets_clean3 <- grep("commnets_clean2", iconv(commnets_clean2, "latin1", "ASCII", sub="commnets_clean2"))
commnets_clean4 <- commnets_clean2[-commnets_clean3]
commnets_clean <- paste(commnets_clean4, collapse = ", ")
```
```{r}
stopwords1 <- c("the", "this")
commnets_corpus  <-Corpus(VectorSource(commnets_clean))
commnets_function <- content_transformer(function(x,pattern)gsub(pattern," ",x))
commnets_corpus_clean <- tm_map(commnets_corpus,removeWords, stopwords("english"))
commnets_corpus_clean <- tm_map(commnets_corpus,commnets_function,"/")
commnets_corpus_clean <- tm_map(commnets_corpus,commnets_function,"@")
commnets_corpus_clean <- tm_map(commnets_corpus,commnets_function,"\\|")
commnets_corpus_clean <- tm_map(commnets_corpus,commnets_function,"??")
commnets_corpus_clean <- tm_map(commnets_corpus,commnets_function,"???")
commnets_corpus_clean <- tm_map(commnets_corpus,content_transformer(tolower))
commnets_corpus_clean <- tm_map(commnets_corpus,removePunctuation)
commnets_corpus_clean <- tm_map(commnets_corpus,stripWhitespace)
```
```{r}
term_matrix <-TermDocumentMatrix(commnets_corpus_clean)
term_matrix_b<-as.matrix(term_matrix)
words <- sort(rowSums(term_matrix_b),decreasing = TRUE)
term_frame<-data.frame(word=names(words),freq=words)
term_frame <- subset(term_frame, word!="youtu" & word!="https" & word!="the" & word!="this" & word!="http" & word!="com" & word!="shall"& word!="www")
write.csv(term_frame, file = "term_frame.csv", row.names = FALSE)
```
```{r}
term_frame
```